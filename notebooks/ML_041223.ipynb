{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузите датасет для классификации кошек и собак: https://drive.google.com/file/d/1YQ2PX-BZ_7uZ216qmAnx-nTCaEqozuCZ/view?usp=share_link.\n",
    "2. Загрузите датасет с множеством различных классов: https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip. Выберите 3 любых класса, которые вам нравятся.\n",
    "3. Загрузите данные и сформируете датасет. Выполните минимум две аугментации. Соберите сверточную нейронную сеть с помощью фреймворка Tensorflow и решите задачу классификации кошек и собак. Оцените модель. Будьте готовы ответить на вопросы:\n",
    "    - какие этапы предварительной обработки данных вы делаете и что происходит с данными?\n",
    "    - что означают параметры, которые вы задаете?\n",
    "    - какие слои у вас есть и что происходит на каждом слое?\n",
    "    \n",
    "<b>Обращаю внимание: </b> допускается несдача ЛР даже если все сделано правильно, но на вопросы ответы не предоставлены (либо неверны).\n",
    "\n",
    "4. Загрузите модели InceptionV3 и VGG19 с помощью Tensorflow. Выполните transfer learning и fine-tuning этих моделей для распознавания выбранных на 2 пункте классов. В процессе подготовки сетей, разморозьте какой-либо еще слой, кроме последнего. Сравните результаты двух сетей на ваших данных (по метрике accuracy в процессе обучения).\n",
    "5. Используйте реализацию многослойного персептрона из ЛР 4. Реализуйте сверточный слой (прямое и обратное распространение). Соберите сверточную сеть. Попробуйте обучить классификатор кошек и собак с использованием собственной реализации сверточной нейронной сети. Вам также потребуется реализовать слой для преобразования многомерных массивов данных в одномерные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"C://Users//MSI//Desktop//OmSTU//MachineLearning//models//Neyron\")\n",
    "from multilayer_perceptron import MultilayerPerceptronModel\n",
    "from image_preproccessing import tf_to_ndarray, to_1D_array\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Using 1800 files for training.\n",
      "Using 200 files for validation.\n",
      "Found 196 files belonging to 3 classes.\n",
      "Using 177 files for training.\n",
      "Using 19 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data3, test_data3 = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../data/data3\",\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(128,128),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "train_data4, test_data4 = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../data/data4\",\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MSI\\Desktop\\OmSTU\\MachineLearning\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),\n",
    "    ]\n",
    ")\n",
    "augmentation = lambda img, label: (data_augmentation(img), label)\n",
    "\n",
    "train_data3 = train_data3.map(augmentation)\n",
    "train_data3 = train_data3.map(augmentation)\n",
    "train_data4 = train_data4.map(augmentation)\n",
    "train_data4 = train_data4.map(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 128, 128, 3)\n",
      "(1, 1800)\n",
      "(200, 128, 128, 3)\n",
      "(1, 200)\n",
      "(49152, 1800)\n",
      "(49152, 200)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = tf_to_ndarray(train_data3)\n",
    "test_x, test_y = tf_to_ndarray(test_data3)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "train_x = to_1D_array(train_x)\n",
    "test_x = to_1D_array(test_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# входной слой - размер (200, 400, 3)\n",
    "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
    "# преобразуем значения пикселей из [0, 255] к [0, 1]\n",
    "x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "# первый сверточный слой\n",
    "x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "# первый пулинг\n",
    "x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "# второй сверточный слой\n",
    "x = tf.keras.layers.Conv2D(128, 4, strides=2, padding=\"valid\")(x)\n",
    "# второй пулинг\n",
    "x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "# выпрямляем многомерный массив\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# полносвязный слой с 64 нейронами\n",
    "x = tf.keras.layers.Dense(32, activation=\"tanh\")(x)\n",
    "# выходной слой с функцией sofrmax\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 300, 300, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 300, 300, 3)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 75, 75, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 128)       65664     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 18, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1327136   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393,762\n",
      "Trainable params: 1,393,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем сеть, указываем, что будем при обучении смотреть значения accuracy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "113/113 [==============================] - 43s 369ms/step - loss: 0.7185 - accuracy: 0.5572 - val_loss: 0.6968 - val_accuracy: 0.5700\n",
      "Epoch 2/5\n",
      "113/113 [==============================] - 38s 333ms/step - loss: 0.6607 - accuracy: 0.6011 - val_loss: 0.6218 - val_accuracy: 0.6100\n",
      "Epoch 3/5\n",
      "113/113 [==============================] - 38s 333ms/step - loss: 0.6291 - accuracy: 0.6383 - val_loss: 0.5900 - val_accuracy: 0.6700\n",
      "Epoch 4/5\n",
      "113/113 [==============================] - 39s 348ms/step - loss: 0.6237 - accuracy: 0.6500 - val_loss: 0.5891 - val_accuracy: 0.6950\n",
      "Epoch 5/5\n",
      "113/113 [==============================] - 40s 349ms/step - loss: 0.6083 - accuracy: 0.6711 - val_loss: 0.5625 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17587477700>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# начинаем обучение\n",
    "# указываем validation_data - при обучении будем получать accuracy для тестовой выборки\n",
    "model.fit(train_data3, epochs=5, validation_data=test_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2622296 , 0.73777044]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    \"../data/data3/dogs/4.jpg\", target_size=(300, 300)\n",
    ")\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
